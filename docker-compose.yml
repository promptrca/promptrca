services:
  promptrca-server:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: promptrca-server
    environment:
      - AWS_REGION=${AWS_REGION:-eu-west-1}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_SESSION_TOKEN=${AWS_SESSION_TOKEN:-}
      - BEDROCK_MODEL_ID=${BEDROCK_MODEL_ID:-openai.gpt-oss-120b-1:0}
      - PROMPTRCA_ORCHESTRATOR_MODEL_ID=${PROMPTRCA_ORCHESTRATOR_MODEL_ID:-openai.gpt-oss-120b-1:0}
      - PROMPTRCA_TEMPERATURE=${PROMPTRCA_TEMPERATURE:-0.7}
      - PROMPTRCA_MAX_TOKENS=${PROMPTRCA_MAX_TOKENS:-2048}
      - PROMPTRCA_PARSER_MAX_TOKENS=${PROMPTRCA_PARSER_MAX_TOKENS:-512}
      - AWS_KNOWLEDGE_MCP_URL=${AWS_KNOWLEDGE_MCP_URL:-https://knowledge-mcp.global.api.aws}
      - AWS_KNOWLEDGE_MCP_ENABLED=${AWS_KNOWLEDGE_MCP_ENABLED:-true}
      - AWS_KNOWLEDGE_MCP_TIMEOUT=${AWS_KNOWLEDGE_MCP_TIMEOUT:-30}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT}
      - OTEL_SERVICE_NAME=${OTEL_SERVICE_NAME:-promptrca-server}
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
      - LANGFUSE_HOST=${LANGFUSE_HOST}
      # Swarm Orchestrator (Strands best practices, autonomous agent coordination)
      - PROMPTRCA_ORCHESTRATOR=swarm
      # Swarm Performance Configuration
      - SWARM_MAX_HANDOFFS=${SWARM_MAX_HANDOFFS:-5}
      - SWARM_MAX_ITERATIONS=${SWARM_MAX_ITERATIONS:-3}
      - SWARM_EXECUTION_TIMEOUT=${SWARM_EXECUTION_TIMEOUT:-90.0}
      - SWARM_NODE_TIMEOUT=${SWARM_NODE_TIMEOUT:-30.0}
    ports:
      - "8080:8080"
    networks:
      - promptrca-network
    volumes:
      - ./src/promptrca:/app/promptrca:ro  # Hot reloading for development
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  promptrca-lambda:
    build:
      context: .
      dockerfile: Dockerfile.lambda
    container_name: promptrca-lambda
    environment:
      - AWS_REGION=${AWS_REGION:-eu-west-1}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_SESSION_TOKEN=${AWS_SESSION_TOKEN:-}
      - BEDROCK_MODEL_ID=${BEDROCK_MODEL_ID:-openai.gpt-oss-120b-1:0}
      - PROMPTRCA_ORCHESTRATOR_MODEL_ID=${PROMPTRCA_ORCHESTRATOR_MODEL_ID:-openai.gpt-oss-120b-1:0}
      - PROMPTRCA_TEMPERATURE=${PROMPTRCA_TEMPERATURE:-0.7}
      - PROMPTRCA_MAX_TOKENS=${PROMPTRCA_MAX_TOKENS:-2048}
      - PROMPTRCA_PARSER_MAX_TOKENS=${PROMPTRCA_PARSER_MAX_TOKENS:-512}
      - AWS_KNOWLEDGE_MCP_URL=${AWS_KNOWLEDGE_MCP_URL:-https://knowledge-mcp.global.api.aws}
      - AWS_KNOWLEDGE_MCP_ENABLED=${AWS_KNOWLEDGE_MCP_ENABLED:-true}
      - AWS_KNOWLEDGE_MCP_TIMEOUT=${AWS_KNOWLEDGE_MCP_TIMEOUT:-30}
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT}
      - OTEL_SERVICE_NAME=${OTEL_SERVICE_NAME:-promptrca-lambda}
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
      - LANGFUSE_HOST=${LANGFUSE_HOST}
      # Swarm Orchestrator (Strands best practices, autonomous agent coordination)
      - PROMPTRCA_ORCHESTRATOR=swarm
      # Swarm Performance Configuration
      - SWARM_MAX_HANDOFFS=${SWARM_MAX_HANDOFFS:-5}
      - SWARM_MAX_ITERATIONS=${SWARM_MAX_ITERATIONS:-3}
      - SWARM_EXECUTION_TIMEOUT=${SWARM_EXECUTION_TIMEOUT:-90.0}
      - SWARM_NODE_TIMEOUT=${SWARM_NODE_TIMEOUT:-30.0}
    ports:
      - "9001:8080"  # Lambda RIE listens on port 8080 inside container
    networks:
      - promptrca-network
    volumes:
      - ./src/promptrca:/var/task/promptrca:ro  # Hot reloading for development
    healthcheck:
      # Lambda RIE doesn't have a simple health endpoint, so we check if the process is running
      test: ["CMD-SHELL", "ps aux | grep -v grep | grep -q 'lambda-runtime-api' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 2048M  # Lambda typically needs more memory
          cpus: '1.0'

networks:
  promptrca-network:
    driver: bridge
